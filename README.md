# üöÄ Meu Estudo de Classifica√ß√£o de Gatos e Cachorros com Transfer Learning (MobileNetV2)

## üìñ Descri√ß√£o do Estudo

Neste projeto, realizei um estudo pr√°tico de **Transfer Learning** para resolver um problema cl√°ssico de classifica√ß√£o de imagens: diferenciar gatos de cachorros. Meu objetivo era construir um modelo de alta precis√£o sem o custo computacional de treinar uma rede neural profunda do zero.

Para isso, utilizei o modelo pr√©-treinado **MobileNetV2** e o adaptei para esta tarefa.

Um dos principais desafios que enfrentei foi o tempo de treinamento. O dataset completo √© grande e uma √∫nica √©poca poderia levar horas. Para resolver isso e conseguir iterar mais r√°pido, decidi usar uma estrat√©gia de **prototipagem r√°pida**, utilizando apenas **15%** do conjunto de dados para o treinamento inicial.

## üí° Conceitos que Apliquei

Este projeto foi centrado em dois conceitos fundamentais de Deep Learning:

### Transfer Learning (Feature Extraction)

* **O que eu fiz:** Em vez de come√ßar do zero, eu carreguei o MobileNetV2 j√° treinado na base de dados ImageNet.
* **Por que fiz isso?** Esse modelo j√° "sabe" identificar caracter√≠sticas visuais complexas (bordas, texturas, formas). Eu "congelei" os pesos dessas camadas e apenas treinei uma nova camada de classifica√ß√£o no topo, que adicionei manualmente.
* **Vantagem:** Isso reduziu drasticamente o tempo de treinamento e a necessidade de dados, me permitindo alcan√ßar uma alta precis√£o rapidamente.

### Fine-Tuning (Ajuste Fino)

* **O que eu fiz:** Ap√≥s o primeiro treinamento, eu "descongelei" algumas das camadas superiores do MobileNetV2.
* **Por que fiz isso?** Isso permitiu que o modelo ajustasse levemente suas caracter√≠sticas mais abstratas para se especializarem no meu problema (diferenciar gatos de cachorros, em vez de 1000 classes gen√©ricas).
* **Como?** Eu continuei o treinamento, mas com uma **taxa de aprendizado (learning rate) muito baixa**. Isso foi crucial para n√£o "estragar" o conhecimento valioso que o modelo j√° possu√≠a.

## üíæ O Conjunto de Dados: `cats_vs_dogs`

* **Fonte:** `tensorflow_datasets` (TFDS).
* **Desafio:** O dataset original s√≥ tem um split de `train` (cerca de 23.000 imagens), o que tornava o treinamento inicial muito lento (o Colab estimou horas, com 582 passos por √©poca).
* **Minha Solu√ß√£o (Prototipagem R√°pida):** Para testar minha arquitetura de modelo rapidamente, eu dividi manualmente o dataset usando "slices" (fatias) do TFDS.

Minhas divis√µes foram:

* **Treinamento:** `train[:15%]` (Os primeiros 15% dos dados)
* **Valida√ß√£o:** `train[15%:20%]` (Os pr√≥ximos 5%)
* **Teste:** `train[20%:25%]` (Os 5% seguintes)

Isso me deu um conjunto de dados pequeno o suficiente para treinar em minutos, permitindo-me validar minha abordagem antes de escalar.

## üî¨ Minha Metodologia (Pipeline do C√≥digo)

Eu estruturei meu c√≥digo em 6 etapas claras:

### 1. Carregamento dos Dados

* Carreguei o `cats_vs_dogs` do TFDS usando os splits de 15%/5%/5% que defini.
* Usei `as_supervised=True` para carregar os dados no formato `(imagem, label)`.

### 2. Pr√©-processamento

* Criei uma fun√ß√£o para redimensionar as imagens para `(160, 160)`, o tamanho de entrada que o MobileNetV2 espera.
* Apliquei a fun√ß√£o `tf.keras.applications.mobilenet_v2.preprocess_input`, que normaliza os pixels para o intervalo `[-1, 1]`.
* Preparei o pipeline de dados com `.shuffle()`, `.batch()` e `.prefetch()` para garantir um treinamento eficiente.

### 3. Cria√ß√£o do Modelo (Feature Extraction)

* Carreguei o MobileNetV2 com `weights='imagenet'` e `include_top=False` (para remover a camada de classifica√ß√£o original).
* "Congelei" o modelo base definindo `base_model.trainable = False`.
* Adicionei minha pr√≥pria "cabe√ßa" de classifica√ß√£o no topo:
    * `GlobalAveragePooling2D`: Para achatar os mapas de caracter√≠sticas.
    * `Dropout(0.2)`: Para regulariza√ß√£o.
    * `Dense(1, activation='sigmoid')`: Minha camada de sa√≠da. Escolhi 1 neur√¥nio com `sigmoid` por ser um problema de classifica√ß√£o bin√°ria.

### 4. Compila√ß√£o e Treinamento (Fase 1)

* Compilei o modelo com `Adam`, perda `binary_crossentropy` e m√©trica `accuracy`.
* Treinei o modelo por 10 √©pocas, observando a performance nos dados de valida√ß√£o.

### 5. Ajuste Fino (Fase 2)

* Defini `base_model.trainable = True` para "descongelar" o modelo.
* Decidi re-congelar as primeiras 100 camadas (`fine_tune_at = 100`) para proteger os pesos mais b√°sicos e treinar apenas as camadas mais abstratas.
* Recompilei o modelo com uma taxa de aprendizado 10x menor (`0.00001`).
* Continuei o treinamento por mais 10 √©pocas.

### 6. Avalia√ß√£o

* Avaliei o desempenho final no conjunto de teste (dados que o modelo nunca viu durante o treino ou valida√ß√£o).
* Plotei os gr√°ficos de acur√°cia e perda (Treino vs. Valida√ß√£o) para analisar visualmente o progresso e verificar se houve overfitting.

## üíª Como Executar

* **Ambiente:** Usei o Google Colab para este estudo.
* **Acelerador:** Habilitei a GPU gratuita (Ambiente de execu√ß√£o -> Alterar tipo de ambiente de execu√ß√£o -> GPU).
* **Execu√ß√£o:** Colei o script `cats_vs_dogs_transfer_15pct.py` em uma c√©lula e executei.

## üìä O que eu observei

Mesmo treinando em apenas **15%** dos dados, o poder do Transfer Learning foi impressionante. Consegui uma acur√°cia de valida√ß√£o e teste muito alta (acima de 95%) em pouqu√≠ssimo tempo. O fine-tuning ajudou a "polir" o modelo e ganhar mais alguns pontos de precis√£o.

Este estudo foi uma √≥tima valida√ß√£o de que √© poss√≠vel desenvolver modelos de vis√£o computacional de alta performance sem dias de treinamento, e me ensinou uma estrat√©gia eficaz para prototipar rapidamente.
